{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "DIM=128 \n",
    "BS=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images('newcommand/'))\n",
    "data_cmd = []\n",
    "labels_cmd = []\n",
    "id_date_list_cmd = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (DIM, DIM))\n",
    "    arr=imagePath.split('_')\n",
    "    if image.sum()!=(DIM*DIM*3*255):\n",
    "        data_cmd.append(image)\n",
    "        labels_cmd.append(label)\n",
    "        id_date_list_cmd.append(arr[1]+'-'+arr[2]+'_'+arr[3])\n",
    "\n",
    "data_cmd = np.array(data_cmd, dtype=\"float\") / 255.0\n",
    "le = LabelEncoder()\n",
    "labels_cmd = le.fit_transform(labels_cmd)\n",
    "labels_cmd = to_categorical(labels_cmd, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images('newcopy/'))\n",
    "data_cop = []\n",
    "labels_cop = []\n",
    "id_date_list_cop = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (DIM, DIM))\n",
    "    arr=imagePath.split('_')\n",
    "    if image.sum()!=(DIM*DIM*3*255):\n",
    "        data_cop.append(image)\n",
    "        labels_cop.append(label)\n",
    "        id_date_list_cop.append(arr[1]+'-'+arr[2]+'_'+arr[3])\n",
    "\n",
    "data_cop = np.array(data_cop, dtype=\"float\") / 255.0\n",
    "le = LabelEncoder()\n",
    "labels_cop = le.fit_transform(labels_cop)\n",
    "labels_cop = to_categorical(labels_cop, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "train_id = []\n",
    "test_id = []\n",
    "for train_index, test_index in sss.split(range(len(labels_cmd)), labels_cmd[:,0]):\n",
    "    train_id.append(train_index)\n",
    "    test_id.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "\t\trotation_range=10,\n",
    "\t\tzoom_range=0.15,\n",
    "\t\twidth_shift_range=0.1,\n",
    "\t\theight_shift_range=0.1,\n",
    "\t\tshear_range=0.15,\n",
    "\t\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (DIM, DIM, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model\n",
    "base_model_cmd = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n",
    "#base_model_cmd = tf.keras.applications.DenseNet121(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "#5\n",
      "#6\n",
      "#7\n",
      "#8\n",
      "#9\n",
      "#10\n",
      "#11\n",
      "#12\n",
      "#13\n",
      "#14\n",
      "#15\n",
      "#16\n",
      "#17\n",
      "#18\n",
      "#19\n",
      "WARNING:tensorflow:From /Users/samadamini/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/samadamini/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model_cmd0/assets\n",
      "#0\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "#5\n",
      "#6\n",
      "#7\n",
      "#8\n",
      "#9\n",
      "#10\n",
      "#11\n",
      "#12\n",
      "#13\n",
      "#14\n",
      "#15\n",
      "#16\n",
      "#17\n",
      "#18\n",
      "#19\n",
      "INFO:tensorflow:Assets written to: model_cmd1/assets\n",
      "#0\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "#5\n",
      "#6\n",
      "#7\n",
      "#8\n",
      "#9\n",
      "#10\n",
      "#11\n",
      "#12\n",
      "#13\n",
      "#14\n",
      "#15\n",
      "#16\n",
      "#17\n",
      "#18\n",
      "#19\n",
      "INFO:tensorflow:Assets written to: model_cmd2/assets\n",
      "#0\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "#5\n",
      "#6\n",
      "#7\n",
      "#8\n",
      "#9\n",
      "#10\n",
      "#11\n",
      "#12\n",
      "#13\n",
      "#14\n",
      "#15\n",
      "#16\n",
      "#17\n",
      "#18\n",
      "#19\n",
      "INFO:tensorflow:Assets written to: model_cmd3/assets\n",
      "#0\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "#5\n",
      "#6\n",
      "#7\n",
      "#8\n",
      "#9\n",
      "#10\n",
      "#11\n",
      "#12\n",
      "#13\n",
      "#14\n",
      "#15\n",
      "#16\n",
      "#17\n",
      "#18\n",
      "#19\n",
      "INFO:tensorflow:Assets written to: model_cmd4/assets\n"
     ]
    }
   ],
   "source": [
    "#Training Deep learning model\n",
    "for m in range(5):\n",
    "    X_traincmd = data_cmd[train_id[m]]\n",
    "    y_traincmd =labels_cmd[train_id[m]]\n",
    "    X_testcmd =data_cmd[test_id[m]]\n",
    "    y_testcmd =labels_cmd[test_id[m]]\n",
    "\n",
    "    d_idx = [idx for idx, val in enumerate(y_traincmd) if val[0]==1] \n",
    "    n_idx = [idx for idx, val in enumerate(y_traincmd) if val[1]==1] \n",
    "    random.shuffle(n_idx)\n",
    "    undersamples = len(d_idx)\n",
    "    stacked_x = []\n",
    "    stacked_y= []\n",
    "    for i in range(20):\n",
    "        train_idx = n_idx[i*undersamples:(i+1)*undersamples] + d_idx\n",
    "        X_traincmd1 = X_traincmd[train_idx]\n",
    "        y_traincmd1 = y_traincmd[train_idx]\n",
    "        stacked_x.append(X_traincmd1)\n",
    "        stacked_y.append(y_traincmd1)\n",
    "\n",
    "    base_model_cmd.trainable = False\n",
    "    model_cmd = tf.keras.Sequential([\n",
    "      base_model_cmd,\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4)#3e-4\n",
    "    model_cmd.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy','binary_crossentropy',tf.keras.metrics.AUC()])\n",
    "\n",
    "    for i in range(20):\n",
    "        model_cmd.fit(x=aug.flow(stacked_x[i], stacked_y[i], batch_size=BS),\n",
    "                #validation_data=(X_testcmd, y_testcmd),\n",
    "                steps_per_epoch=len(stacked_x[i]) // BS,\n",
    "                verbose=0,\n",
    "                epochs=20)\n",
    "        print(\"#{}\".format(i))\n",
    "\n",
    "    model_cmd.save(\"model_cmd{}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.41      0.25        32\n",
      "         1.0       0.97      0.91      0.94       652\n",
      "\n",
      "    accuracy                           0.88       684\n",
      "   macro avg       0.57      0.66      0.59       684\n",
      "weighted avg       0.93      0.88      0.91       684\n",
      "\n",
      "auc_model0: 0.7736771472392638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.50      0.26        32\n",
      "         1.0       0.97      0.89      0.93       652\n",
      "\n",
      "    accuracy                           0.87       684\n",
      "   macro avg       0.58      0.69      0.60       684\n",
      "weighted avg       0.94      0.87      0.90       684\n",
      "\n",
      "auc_model1: 0.7715203220858895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.56      0.27        32\n",
      "         1.0       0.98      0.88      0.92       652\n",
      "\n",
      "    accuracy                           0.86       684\n",
      "   macro avg       0.58      0.72      0.60       684\n",
      "weighted avg       0.94      0.86      0.89       684\n",
      "\n",
      "auc_model2: 0.813506518404908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.66      0.37        32\n",
      "         1.0       0.98      0.91      0.94       652\n",
      "\n",
      "    accuracy                           0.90       684\n",
      "   macro avg       0.62      0.78      0.66       684\n",
      "weighted avg       0.95      0.90      0.92       684\n",
      "\n",
      "auc_model3: 0.8897622699386503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.41      0.24        32\n",
      "         1.0       0.97      0.90      0.93       652\n",
      "\n",
      "    accuracy                           0.88       684\n",
      "   macro avg       0.57      0.65      0.59       684\n",
      "weighted avg       0.93      0.88      0.90       684\n",
      "\n",
      "auc_model4: 0.8163822852760736\n"
     ]
    }
   ],
   "source": [
    "#Results for the deep learning model\n",
    "for i in range(5):\n",
    "    model_cmd = keras.models.load_model(\"model_cmd{}\".format(i))\n",
    "    y_testcmd =labels_cmd[test_id[i]]\n",
    "    y_pred=model_cmd.predict(data_cmd[test_id[i]])\n",
    "    y_pred_label=((y_pred[:,1]>0.5)*1.0).flatten()\n",
    "    print(metrics.classification_report(y_testcmd[:,1], y_pred_label))\n",
    "    auc=metrics.roc_auc_score(y_testcmd.astype(int), y_pred)\n",
    "    print('auc_model{}: '.format(i)+str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load labels\n",
    "df1=pd.read_csv('fhs_csk/20200615/metadata/rekey_revalue_(2292)_[2302]_2020061748_first_dct_replace_metadata_20200615.csv') \n",
    "df2=pd.read_csv('fhs_csk/20200615/metadata/rekey_revalue_(1758)_[1814]_2020061751_second_dct_replace_metadata_20200615.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_model0: 0.9546783625730995\n",
      "auc_model0: 0.8830042177914111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       652\n",
      "           1       0.35      0.25      0.29        32\n",
      "\n",
      "    accuracy                           0.94       684\n",
      "   macro avg       0.66      0.61      0.63       684\n",
      "weighted avg       0.93      0.94      0.94       684\n",
      "\n",
      "accuracy_model1: 0.9517543859649122\n",
      "auc_model1: 0.9033742331288344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       652\n",
      "           1       0.45      0.31      0.37        32\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.71      0.65      0.67       684\n",
      "weighted avg       0.94      0.95      0.95       684\n",
      "\n",
      "accuracy_model2: 0.9576023391812866\n",
      "auc_model2: 0.9099884969325154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       652\n",
      "           1       0.40      0.38      0.39        32\n",
      "\n",
      "    accuracy                           0.94       684\n",
      "   macro avg       0.68      0.67      0.68       684\n",
      "weighted avg       0.94      0.94      0.94       684\n",
      "\n",
      "accuracy_model3: 0.9605263157894737\n",
      "auc_model3: 0.9266200153374232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       652\n",
      "           1       0.56      0.31      0.40        32\n",
      "\n",
      "    accuracy                           0.96       684\n",
      "   macro avg       0.76      0.65      0.69       684\n",
      "weighted avg       0.95      0.96      0.95       684\n",
      "\n",
      "accuracy_model4: 0.9546783625730995\n",
      "auc_model4: 0.9094612730061349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       652\n",
      "           1       0.50      0.25      0.33        32\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.73      0.62      0.65       684\n",
      "weighted avg       0.94      0.95      0.95       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training and the results for the ensemble model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "coeff = []\n",
    "for m in range(5):\n",
    "    df = pd.concat([df1,df2])\n",
    "    df[\"diagnosis\"] = df[\"diagnosis\"].apply(lambda a: int(float(a)>0))\n",
    "    df[\"cnn_command\"] =np.NaN\n",
    "    df[\"cnn_copy\"] =np.NaN\n",
    "    df=df[['id_date','age_at_event','cnn_command','cnn_copy','diagnosis']]\n",
    "    cnn_command_list = keras.models.load_model(\"model_cmd{}\".format(m)).predict(data_cmd)\n",
    "    cnn_copy_list = keras.models.load_model(\"model_cmd{}\".format(m)).predict(data_cop)\n",
    "    for i in range(len(data_cmd)):\n",
    "        id_date=id_date_list_cmd[i]\n",
    "        cnn_command = cnn_command_list[i][0]\n",
    "        df.loc[df.id_date == id_date, 'cnn_command'] = cnn_command\n",
    "    for i in range(len(data_cop)):\n",
    "        id_date=id_date_list_cop[i]\n",
    "        cnn_copy = cnn_copy_list[i][0]\n",
    "        df.loc[df.id_date == id_date, 'cnn_copy'] = cnn_copy\n",
    "        \n",
    "        \n",
    "    df['cnn_copy'] = df['cnn_copy'].fillna(df['cnn_copy'].mean())\n",
    "    df = df.dropna()\n",
    "    \n",
    "    test=df[df['id_date'].isin(np.array(id_date_list_cmd)[test_id[m]])]\n",
    "    train=df[df['id_date'].isin(np.array(id_date_list_cmd)[train_id[m]])]\n",
    "    y_train=train.diagnosis\n",
    "    x_train=train.drop(columns=[\"diagnosis\",\"id_date\"])\n",
    "    y_test=test.diagnosis\n",
    "    x_test=test.drop(columns=[\"diagnosis\",\"id_date\"])\n",
    "    \n",
    "    model_log = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model_log.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred=model_log.predict_proba(np.asarray(x_test))\n",
    "    accuracy=metrics.accuracy_score(np.asarray(y_test), (1*(np.array(y_pred[:,1])>0.5)).tolist())\n",
    "    print('accuracy_model{}: '.format(m)+str(accuracy))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(np.array(y_test), np.array(y_pred[:,1]))\n",
    "    auc=metrics.auc(fpr, tpr)\n",
    "    print('auc_model{}: '.format(m)+str(auc))\n",
    "    print(metrics.classification_report(np.asarray(y_test), np.array(y_pred[:,1])>0.32))\n",
    "    \n",
    "    x_train[\"age_at_event\"] = x_train[\"age_at_event\"].apply(lambda a: a/100)\n",
    "    x_test[\"age_at_event\"] = x_test[\"age_at_event\"].apply(lambda a: a/100)\n",
    "    model_log = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model_log.fit(x_train, y_train)\n",
    "    coeff.append(model_log.coef_[0])\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgl = np.zeros(len(coeff[0]))\n",
    "for i, lists in enumerate(coeff):\n",
    "    avgl = avgl + lists\n",
    "avgl = avgl/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.bar([\"Age\",\"Command\",\"Copy\"], avgl)\n",
    "pyplot.xticks(rotation=0)\n",
    "pyplot.savefig(\"avginterp\")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
