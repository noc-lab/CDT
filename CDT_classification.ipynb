{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "DIM=128 \n",
    "BS=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images('newcommand/'))\n",
    "data_cmd = []\n",
    "labels_cmd = []\n",
    "id_date_list_cmd = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (DIM, DIM))\n",
    "    arr=imagePath.split('_')\n",
    "    if image.sum()!=(DIM*DIM*3*255):\n",
    "        data_cmd.append(image)\n",
    "        labels_cmd.append(label)\n",
    "        id_date_list_cmd.append(arr[1]+'-'+arr[2]+'_'+arr[3])\n",
    "\n",
    "data_cmd = np.array(data_cmd, dtype=\"float\") / 255.0\n",
    "le = LabelEncoder()\n",
    "labels_cmd = le.fit_transform(labels_cmd)\n",
    "labels_cmd = to_categorical(labels_cmd, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images('newcopy/'))\n",
    "data_cop = []\n",
    "labels_cop = []\n",
    "id_date_list_cop = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (DIM, DIM))\n",
    "    arr=imagePath.split('_')\n",
    "    if image.sum()!=(DIM*DIM*3*255):\n",
    "        data_cop.append(image)\n",
    "        labels_cop.append(label)\n",
    "        id_date_list_cop.append(arr[1]+'-'+arr[2]+'_'+arr[3])\n",
    "\n",
    "data_cop = np.array(data_cop, dtype=\"float\") / 255.0\n",
    "le = LabelEncoder()\n",
    "labels_cop = le.fit_transform(labels_cop)\n",
    "labels_cop = to_categorical(labels_cop, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "train_id = []\n",
    "test_id = []\n",
    "for train_index, test_index in sss.split(range(len(labels_cmd)), labels_cmd[:,0]):\n",
    "    train_id.append(train_index)\n",
    "    test_id.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "\t\trotation_range=10,\n",
    "\t\tzoom_range=0.15,\n",
    "\t\twidth_shift_range=0.1,\n",
    "\t\theight_shift_range=0.1,\n",
    "\t\tshear_range=0.15,\n",
    "\t\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (DIM, DIM, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model\n",
    "base_model_cmd = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n",
    "#base_model_cmd = tf.keras.applications.DenseNet121(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Deep learning model\n",
    "for m in range(5):\n",
    "    X_traincmd = data_cmd[train_id[m]]\n",
    "    y_traincmd =labels_cmd[train_id[m]]\n",
    "    X_testcmd =data_cmd[test_id[m]]\n",
    "    y_testcmd =labels_cmd[test_id[m]]\n",
    "\n",
    "    d_idx = [idx for idx, val in enumerate(y_traincmd) if val[0]==1] \n",
    "    n_idx = [idx for idx, val in enumerate(y_traincmd) if val[1]==1] \n",
    "    random.shuffle(n_idx)\n",
    "    undersamples = len(d_idx)\n",
    "    stacked_x = []\n",
    "    stacked_y= []\n",
    "    for i in range(20):\n",
    "        train_idx = n_idx[i*undersamples:(i+1)*undersamples] + d_idx\n",
    "        X_traincmd1 = X_traincmd[train_idx]\n",
    "        y_traincmd1 = y_traincmd[train_idx]\n",
    "        stacked_x.append(X_traincmd1)\n",
    "        stacked_y.append(y_traincmd1)\n",
    "\n",
    "    base_model_cmd.trainable = False\n",
    "    model_cmd = tf.keras.Sequential([\n",
    "      base_model_cmd,\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4)#3e-4\n",
    "    model_cmd.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy','binary_crossentropy',tf.keras.metrics.AUC()])\n",
    "\n",
    "    for i in range(20):\n",
    "        model_cmd.fit(x=aug.flow(stacked_x[i], stacked_y[i], batch_size=BS),\n",
    "                #validation_data=(X_testcmd, y_testcmd),\n",
    "                steps_per_epoch=len(stacked_x[i]) // BS,\n",
    "                verbose=0,\n",
    "                epochs=20)\n",
    "        #print(\"#{}\".format(i))\n",
    "\n",
    "    model_cmd.save(\"model_cmd{}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.41      0.25        32\n",
      "         1.0       0.97      0.91      0.94       652\n",
      "\n",
      "    accuracy                           0.88       684\n",
      "   macro avg       0.57      0.66      0.59       684\n",
      "weighted avg       0.93      0.88      0.91       684\n",
      "\n",
      "auc_model0: 0.7736771472392638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.50      0.26        32\n",
      "         1.0       0.97      0.89      0.93       652\n",
      "\n",
      "    accuracy                           0.87       684\n",
      "   macro avg       0.58      0.69      0.60       684\n",
      "weighted avg       0.94      0.87      0.90       684\n",
      "\n",
      "auc_model1: 0.7715203220858895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.56      0.27        32\n",
      "         1.0       0.98      0.88      0.92       652\n",
      "\n",
      "    accuracy                           0.86       684\n",
      "   macro avg       0.58      0.72      0.60       684\n",
      "weighted avg       0.94      0.86      0.89       684\n",
      "\n",
      "auc_model2: 0.813506518404908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.66      0.37        32\n",
      "         1.0       0.98      0.91      0.94       652\n",
      "\n",
      "    accuracy                           0.90       684\n",
      "   macro avg       0.62      0.78      0.66       684\n",
      "weighted avg       0.95      0.90      0.92       684\n",
      "\n",
      "auc_model3: 0.8897622699386503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.41      0.24        32\n",
      "         1.0       0.97      0.90      0.93       652\n",
      "\n",
      "    accuracy                           0.88       684\n",
      "   macro avg       0.57      0.65      0.59       684\n",
      "weighted avg       0.93      0.88      0.90       684\n",
      "\n",
      "auc_model4: 0.8163822852760736\n"
     ]
    }
   ],
   "source": [
    "#Results for the deep learning model\n",
    "for i in range(5):\n",
    "    model_cmd = keras.models.load_model(\"model_cmd{}\".format(i))\n",
    "    y_testcmd =labels_cmd[test_id[i]]\n",
    "    y_pred=model_cmd.predict(data_cmd[test_id[i]])\n",
    "    y_pred_label=((y_pred[:,1]>0.5)*1.0).flatten()\n",
    "    accuracy=metrics.accuracy_score(np.asarray(y_testcmd[:,1]), (1*(np.array(y_pred_label[:,1])>0.5)).tolist())\n",
    "    print('accuracy_model{}: '.format(m)+str(accuracy))\n",
    "    print(metrics.classification_report(y_testcmd[:,1], y_pred_label))\n",
    "    auc=metrics.roc_auc_score(y_testcmd.astype(int), y_pred)\n",
    "    print('auc_model{}: '.format(i)+str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load labels\n",
    "df1=pd.read_csv('fhs_csk/20200615/metadata/rekey_revalue_(2292)_[2302]_2020061748_first_dct_replace_metadata_20200615.csv') \n",
    "df2=pd.read_csv('fhs_csk/20200615/metadata/rekey_revalue_(1758)_[1814]_2020061751_second_dct_replace_metadata_20200615.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_model0: 0.9473684210526315\n",
      "auc_model0: 0.904045245398773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       652\n",
      "           1       0.33      0.31      0.32        32\n",
      "\n",
      "    accuracy                           0.94       684\n",
      "   macro avg       0.65      0.64      0.65       684\n",
      "weighted avg       0.94      0.94      0.94       684\n",
      "\n",
      "accuracy_model1: 0.9502923976608187\n",
      "auc_model1: 0.9212998466257669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       652\n",
      "           1       0.37      0.31      0.34        32\n",
      "\n",
      "    accuracy                           0.94       684\n",
      "   macro avg       0.67      0.64      0.65       684\n",
      "weighted avg       0.94      0.94      0.94       684\n",
      "\n",
      "accuracy_model2: 0.9473684210526315\n",
      "auc_model2: 0.9217312116564418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       652\n",
      "           1       0.38      0.34      0.36        32\n",
      "\n",
      "    accuracy                           0.94       684\n",
      "   macro avg       0.67      0.66      0.67       684\n",
      "weighted avg       0.94      0.94      0.94       684\n",
      "\n",
      "accuracy_model3: 0.956140350877193\n",
      "auc_model3: 0.9292082055214724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       652\n",
      "           1       0.58      0.44      0.50        32\n",
      "\n",
      "    accuracy                           0.96       684\n",
      "   macro avg       0.78      0.71      0.74       684\n",
      "weighted avg       0.95      0.96      0.96       684\n",
      "\n",
      "accuracy_model4: 0.9532163742690059\n",
      "auc_model4: 0.921683282208589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       652\n",
      "           1       0.41      0.28      0.33        32\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.69      0.63      0.65       684\n",
      "weighted avg       0.94      0.95      0.94       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "coeff = []\n",
    "for m in range(5):\n",
    "    df = pd.concat([df1,df2])\n",
    "    df[\"diagnosis\"] = df[\"diagnosis\"].apply(lambda a: int(float(a)>0))\n",
    "    df[\"cnn_command\"] =np.NaN\n",
    "    df[\"cnn_copy\"] =np.NaN\n",
    "    df=df[['id_date','age_at_event','cnn_command','cnn_copy','diagnosis']]\n",
    "    cnn_command_list = keras.models.load_model(\"model_cmd{}\".format(m)).predict(data_cmd)\n",
    "    cnn_copy_list = keras.models.load_model(\"model_cmd{}\".format(m)).predict(data_cop)\n",
    "    for i in range(len(data_cmd)):\n",
    "        id_date=id_date_list_cmd[i]\n",
    "        cnn_command = cnn_command_list[i][0]\n",
    "        df.loc[df.id_date == id_date, 'cnn_command'] = cnn_command\n",
    "    for i in range(len(data_cop)):\n",
    "        id_date=id_date_list_cop[i]\n",
    "        cnn_copy = cnn_copy_list[i][0]\n",
    "        df.loc[df.id_date == id_date, 'cnn_copy'] = cnn_copy\n",
    "        \n",
    "        \n",
    "    df['cnn_copy'] = df['cnn_copy'].fillna(df['cnn_copy'].mean())\n",
    "    df = df.dropna()\n",
    "    df['age_at_event'] = df['age_at_event'].apply(lambda a: a/df['age_at_event'].std() - df['age_at_event'].mean()/df['age_at_event'].std())\n",
    "    df['cnn_command'] = df['cnn_command'].apply(lambda a: a/df['cnn_command'].std() - df['cnn_command'].mean()/df['cnn_command'].std())\n",
    "    df['cnn_copy'] = df['cnn_copy'].apply(lambda a: a/df['cnn_copy'].std() - df['cnn_copy'].mean()/df['cnn_copy'].std())\n",
    "\n",
    "    test=df[df['id_date'].isin(np.array(id_date_list_cmd)[test_id[m]])]\n",
    "    train=df[df['id_date'].isin(np.array(id_date_list_cmd)[train_id[m]])]\n",
    "    y_train=train.diagnosis\n",
    "    x_train=train.drop(columns=[\"diagnosis\",\"id_date\"])\n",
    "    y_test=test.diagnosis\n",
    "    x_test=test.drop(columns=[\"diagnosis\",\"id_date\"])\n",
    "    \n",
    "    model_log = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model_log.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred=model_log.predict_proba(np.asarray(x_test))\n",
    "    accuracy=metrics.accuracy_score(np.asarray(y_test), (1*(np.array(y_pred[:,1])>0.5)).tolist())\n",
    "    print('accuracy_model{}: '.format(m)+str(accuracy))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(np.array(y_test), np.array(y_pred[:,1]))\n",
    "    auc=metrics.auc(fpr, tpr)\n",
    "    print('auc_model{}: '.format(m)+str(auc))\n",
    "    print(metrics.classification_report(np.asarray(y_test), np.array(y_pred[:,1])>0.32))\n",
    "    \n",
    "    #x_train[\"age_at_event\"] = x_train[\"age_at_event\"].apply(lambda a: a/100)\n",
    "    #x_test[\"age_at_event\"] = x_test[\"age_at_event\"].apply(lambda a: a/100)\n",
    "    #model_log = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    #model_log.fit(x_train, y_train)\n",
    "    coeff.append(model_log.coef_[0])\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgl = np.zeros(len(coeff[0]))\n",
    "for i, lists in enumerate(coeff):\n",
    "    avgl = avgl + lists\n",
    "avgl = avgl/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP3ElEQVR4nO3dfZBddX3H8feHBPQPfGjJ1jokuoyGalR8WlMdnRqrnUnQkqqMEh9aLZrpTHHaqq2xOlBxOoNlpjC2CE0ppbVT0vhQm0osOooyapEsIg8BcSJSCVVZkTJjHcHIt3/cE3tdNrk3uye75Mf7NZPZe37nu+d8d0/uZ3977j1nU1VIko58Ry11A5KkfhjoktQIA12SGmGgS1IjDHRJasTypdrxihUranJycql2L0lHpGuvvfb7VTUx17olC/TJyUmmp6eXaveSdERK8l8HWucpF0lqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJasSSXSm6EJNbLl/qFpp1+zkvX+oWJM2TM3RJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiJGBnuSSJHcluWlE3fOS7Etyan/tSZLGNc4M/VJg/cEKkiwDPgB8uoeeJEnzMDLQq+oq4Acjyt4GfAy4q4+mJEmHbsHn0JMcD7wSuHCM2s1JppNMz8zMLHTXkqQhfbwoej7wrqp6YFRhVW2tqqmqmpqYmPOPVkuS5qmPe7lMAduSAKwATk6yr6o+0cO2JUljWnCgV9UJ+x8nuRT4pGEuSYtvZKAnuQxYB6xIshc4CzgaoKouOqzdSZLGNjLQq2rTuBurqjctqBtJ0rx5pagkNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiJGBnuSSJHcluekA61+f5IYkNyb5cpJn9t+mJGmUcWbolwLrD7L+W8CLq+oZwPuBrT30JUk6RMtHFVTVVUkmD7L+y0OLVwMrF96WJOlQ9X0O/XTgUwdamWRzkukk0zMzMz3vWpIe3noL9CQvYRDo7zpQTVVtraqpqpqamJjoa9eSJMY45TKOJCcBFwMbquruPrYpSTo0C56hJ3kC8HHgjVX1jYW3JEmaj5Ez9CSXAeuAFUn2AmcBRwNU1UXAmcBxwIeSAOyrqqnD1bAkaW7jvMtl04j1bwHe0ltHkqR58UpRSWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREjAz3JJUnuSnLTAdYnyQeT7ElyQ5Ln9N+mJGmUcWbolwLrD7J+A7C6+7cZuHDhbUmSDtXIQK+qq4AfHKRkI/CPNXA18Ngkj++rQUnSePo4h348cMfQ8t5u7EGSbE4ynWR6Zmamh11LkvZb1BdFq2prVU1V1dTExMRi7lqSmtdHoN8JrBpaXtmNSZIWUR+BvgP47e7dLs8H7q2q7/SwXUnSIVg+qiDJZcA6YEWSvcBZwNEAVXURsBM4GdgD/Ah48+FqVpJ0YCMDvao2jVhfwO/31pEkaV68UlSSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqxFiBnmR9kluT7EmyZY71T0hyZZLrktyQ5OT+W5UkHczIQE+yDLgA2ACsATYlWTOr7L3A9qp6NnAa8KG+G5UkHdw4M/S1wJ6quq2q7ge2ARtn1RTw6O7xY4D/7q9FSdI4xgn044E7hpb3dmPD/gx4Q5K9wE7gbXNtKMnmJNNJpmdmZubRriTpQPp6UXQTcGlVrQROBj6c5EHbrqqtVTVVVVMTExM97VqSBOMF+p3AqqHlld3YsNOB7QBV9Z/AI4EVfTQoSRrPOIG+C1id5IQkxzB40XPHrJpvAy8FSPJUBoHuORVJWkQjA72q9gFnAFcAtzB4N8vuJGcnOaUrewfw1iTXA5cBb6qqOlxNS5IebPk4RVW1k8GLncNjZw49vhl4Yb+tSZIOxViBLi3U5JbLl7qFZt1+zsuXugU9RHjpvyQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRowV6EnWJ7k1yZ4kWw5Q85okNyfZneSf+21TkjTKyL8pmmQZcAHwG8BeYFeSHd0fht5fsxp4N/DCqronyS8droYlSXMbZ4a+FthTVbdV1f3ANmDjrJq3AhdU1T0AVXVXv21KkkYZJ9CPB+4YWt7bjQ07ETgxyZeSXJ1k/VwbSrI5yXSS6ZmZmfl1LEmaU18vii4HVgPrgE3A3yZ57OyiqtpaVVNVNTUxMdHTriVJMF6g3wmsGlpe2Y0N2wvsqKqfVNW3gG8wCHhJ0iIZJ9B3AauTnJDkGOA0YMesmk8wmJ2TZAWDUzC39dinJGmEkYFeVfuAM4ArgFuA7VW1O8nZSU7pyq4A7k5yM3Al8MdVdffhalqS9GAj37YIUFU7gZ2zxs4celzA27t/kqQl4JWiktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiPGCvQk65PcmmRPki0HqXt1kkoy1V+LkqRxjAz0JMuAC4ANwBpgU5I1c9Q9CvgD4Ct9NylJGm2cGfpaYE9V3VZV9wPbgI1z1L0f+ADw4x77kySNaZxAPx64Y2h5bzf2M0meA6yqqst77E2SdAgW/KJokqOAvwTeMUbt5iTTSaZnZmYWumtJ0pBxAv1OYNXQ8spubL9HAU8HPp/kduD5wI65Xhitqq1VNVVVUxMTE/PvWpL0IOME+i5gdZITkhwDnAbs2L+yqu6tqhVVNVlVk8DVwClVNX1YOpYkzWlkoFfVPuAM4ArgFmB7Ve1OcnaSUw53g5Kk8Swfp6iqdgI7Z42deYDadQtvS5J0qLxSVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhox1l8skvTwM7nl8qVuoVm3n/Pyw7JdZ+iS1AgDXZIaMVagJ1mf5NYke5JsmWP925PcnOSGJJ9N8sT+W5UkHczIQE+yDLgA2ACsATYlWTOr7DpgqqpOAj4K/EXfjUqSDm6cGfpaYE9V3VZV9wPbgI3DBVV1ZVX9qFu8GljZb5uSpFHGCfTjgTuGlvd2YwdyOvCpuVYk2ZxkOsn0zMzM+F1Kkkbq9UXRJG8ApoBz51pfVVuraqqqpiYmJvrctSQ97I3zPvQ7gVVDyyu7sZ+T5GXAe4AXV9V9/bQnSRrXODP0XcDqJCckOQY4DdgxXJDk2cDfAKdU1V39tylJGmVkoFfVPuAM4ArgFmB7Ve1OcnaSU7qyc4FjgY8k+VqSHQfYnCTpMBnr0v+q2gnsnDV25tDjl/XclyTpEHmlqCQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktSIsQI9yfoktybZk2TLHOsfkeRfuvVfSTLZd6OSpIMbGehJlgEXABuANcCmJGtmlZ0O3FNVTwbOAz7Qd6OSpIMbZ4a+FthTVbdV1f3ANmDjrJqNwD90jz8KvDRJ+mtTkjTK8jFqjgfuGFreC/zqgWqqal+Se4HjgO8PFyXZDGzuFn+Y5Nb5NH0EWsGs78VDVfzdaj+P2ZHliDlesOBj9sQDrRgn0HtTVVuBrYu5z4eCJNNVNbXUfWh8HrMji8drYJxTLncCq4aWV3Zjc9YkWQ48Bri7jwYlSeMZJ9B3AauTnJDkGOA0YMesmh3A73SPTwU+V1XVX5uSpFFGnnLpzomfAVwBLAMuqardSc4GpqtqB/B3wIeT7AF+wCD09f8edqeZGuAxO7J4vIA4kZakNnilqCQ1wkCXpEYY6D1I8ltJKslTlrqXh4skv5xkW5JvJrk2yc4kJy51X+NIcnuSFUvdx0PdkXyMl4qB3o9NwBe7jzrMuquQ/xX4fFU9qaqeC7wbeNzSdqa+eIznx0BfoCTHAi9icD+b07qxo5J8KMnXk3ymm1mc2q17bpIvdDOOK5I8fgnbP1K9BPhJVV20f6Cqrge+mOTcJDcluTHJawGSrOu+5/+W5LYk5yR5fZJrurondXWXJrkwydVd3boklyS5Jcml+/fV1Uwn2Z3kfUPjtyd5X5Kvdtt9Sjd+XJJPd/UXA94WY7T5HOOrklze3Ujwou55+LtJzt+/jSRvTXLe4n85i8NAX7iNwH9U1TeAu5M8F3gVMMngZmZvBF4AkORo4K+AU7sZxyXAny9F00e4pwPXzjH+KuBZwDOBlwHnDv3AfCbwe8BTGRyTE6tqLXAx8LahbfwCg+P1RwyurzgPeBrwjCTP6mre012VeBLw4iQnDX3+96vqOcCFwDu7sbOAL1bV0xjMOp8w3y/8YWQ+x3gtg2O5BnhSV7sd+M3uuQfwZgbPuyYZ6Au3icENy+g+bmIwY/9IVT1QVd8FruzW/wqD/6ifSfI14L0MrrxVP14EXFZVP62q7wFfAJ7XrdtVVd+pqvuAbwKf7sZvZPDDd79/7y6KuxH4XlXdWFUPALuH6l6T5KvAdQzCfvjuox/vPl47VP9rwD8BVNXlwD0L/1Iftg52jK/pbiL4U+Ay4EVV9UPgc8Arut+Yjq6qG5ek80WwqPdyaU2SXwR+ncHsrRhceFUMZmFzfgqwu6pesEgttmo3gyuSD8V9Q48fGFp+gJ9/Htw3R83P6pKcwGDm/byquqc7FfPIOT7/p/j8Woj5HOPZF9XsX74Y+FPg68DfL7CvhzRn6AtzKvDhqnpiVU1W1SrgWwyuln11dw7vccC6rv5WYCLJz07BJHnaUjR+hPsc8Iju7p0AdKc9/gd4bZJlSSYYzIyv6Xnfjwb+F7i3O7Ybxvicq4DXdX1uYHBaRwc3n2O8trtFyVHAaxm8UYGq+gqDe029jsHMvVnOIBZmEw/+Yx4fY3Cedi9wM4PbCn8VuLeq7u9eHP1gkscw+P6fz2A2ojFVVSV5JXB+kncBPwZuB/4QOBa4nsHs7E+q6rt9vp20qq5Pch2D2d4dwJfG+LT3AZcl2Q18Gfh2X/20ap7HeBfw18CTGZzmHP5NeTvwrKpq+nSXl/4fJkmOraofJjmOwQzihd35dEk9S7IOeGdVveIA6z8JnFdVn13UxhaZM/TD55NJHgscA7zfMJcWX/ccvAa4vvUwB2foktQMXxSVpEYY6JLUCANdkhphoEtSIwx0SWrE/wFvIBgyozgDTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.bar([\"Age\",\"Command\",\"Copy\"], avgl)\n",
    "pyplot.xticks(rotation=0)\n",
    "pyplot.savefig(\"avginterp\")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
